{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Model for User Cellular Package Using Machine Learning <a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mobile operator named `Megaline` was dissatisfied because many of their customers were still using the old package. The company wants to develop a model to analyze consumer behavior and recommend one of the newest Megaline packages: `Smart` or `Ultra`. `Megaline` has a dataset containing the behavior of users of the `Smart` and `Ultra` packages. Here, we will train several `machine learning models` to determine which package to give based on customer behavior (`number of calls`, `call duration`, `sms`, `number of data packets`). In this project, the threshold for the `Accuracy` level is `0.75`. \n",
    "Some of the objectives and formulation of the problem from this project analysis:\n",
    "- Find out the best algorithm for `machine learning` model for `Megaline` dataset.\n",
    "- What is the best `Hyperparameter` in `machine learning` models.\n",
    "- Does the selected `machine learning model` meet the `sanity check`?\n",
    "- Is it true that the selected `machine learning model` can test arbitrary data samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content <a id='back'></a>\n",
    "\n",
    "* [Intro](#intro)\n",
    "* [Content](#back)\n",
    "* [Stage 1. Preparing Dataset](#cont_1)\n",
    "     * [1.1 Loading Library](#cont_2)\n",
    "     * [1.2 Load Dataset](#cont_3)\n",
    "     * [1.3 Checking for Duplication](#cont_4)\n",
    "     * [1.4 Changing Data Type](#cont_5)\n",
    "* [Step 2. Creating a Machine Learning Model](#cont_6)\n",
    "     * [2.1 Splitting Dataset](#cont_7)\n",
    "     * [2.2 Train and Test Machine Learning Algorithms](#cont_8)\n",
    "         * [2.2.1 Decision Tree Classification Algorithm](#cont_9)\n",
    "         * [2.2.2 Random Forest Classification Algorithm](#cont_10)\n",
    "         * [2.2.3 Logistic Regression Algorithm](#cont_11)\n",
    "     * [2.3 Model With Best Algorithm](#cont_12)\n",
    "     * [2.4 Testing Model Eligibility (Sanity Check)](#cont_13)\n",
    "* [Stage 3. Machine Learning Model Application](#cont_14)\n",
    "* [Stage 4. General Conclusion](#cont_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset <a id='cont_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step that needs to be done is to prepare the dataset starting from loading the required library, loading the dataset into the project, checking sample data, checking for missing values, checking for duplicates and checking data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries <a id='cont_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load the required libraries. Here we only need two libraries namely `pandas` to process dataset and `scikit learn` for `machine learning` modeling. Let's load the second library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset <a id='cont_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the `Megaline` dataset into the project using the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the megaline dataset\n",
    "df_megaline = pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will display information and sample data from the `Megaline` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data information\n",
    "print(df_megaline.info())\n",
    "\n",
    "# check sample data\n",
    "df_megaline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains the following fields:\n",
    "- `calls` is the number of calls\n",
    "- `minutes` is the duration of call in minutes\n",
    "- `messages` is the number of messages\n",
    "- `mb_used` is the number of data used in MB\n",
    "- `is_ultra` is the package of ultra. If 1 is `ultra`, 0 is `smart`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the information above, it shows that the dataset consists of `3214 rows` and `5 columns`, has no `missing values`. You can see that the `calls` and `messages` columns have the wrong data type, we will fix this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Duplication <a id='cont_4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will check for duplication in the dataset. If there are many duplicates of the same row, it will reduce the accuracy of the machine learning model that we will create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "df_megaline.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that we do not have the same duplicate data in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Data Type <a id='cont_5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on previous observations, we will change the data type for the `calls` and `messages` columns from `float` to `integer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   int32  \n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   int32  \n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(2), int32(2), int64(1)\n",
      "memory usage: 100.6 KB\n"
     ]
    }
   ],
   "source": [
    "# change the data type of the calls column to integer\n",
    "df_megaline['calls'] = df_megaline['calls'].astype('int')\n",
    "\n",
    "# change the message column data type to integer\n",
    "df_megaline['messages'] = df_megaline['messages'].astype('int')\n",
    "\n",
    "# check the new data type\n",
    "df_megaline.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `calls` and `messages` fields have been successfully converted to `integer` data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Machine Learning Models <a id='cont_6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the best `machine learning model` requires several steps including: dividing the dataset, choosing an algorithm, testing the algorithm, and `tuning hyperparamater`.\n",
    "\n",
    "We will test several `machine learning algorithms` and choose the most effective one to use. Some of these algorithms include:\n",
    "- Decision Tree Classification Algorithm\n",
    "- Random Forest Classification Algorithm\n",
    "- Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset <a id='cont_7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will define what packages are recommended as `target` based on some related `features`. These features include `calls`, `minutes`, `messages` and `mb_used`.\n",
    "\n",
    "Since we only have one dataset, we will divide it into groups to create a `machine learning model`. The division is broken down into `60%` dataset for `training`, `20%` dataset for `validation` and `20%` for `testing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the dataset into 60% training, 20% validation and 20% test\n",
    "\n",
    "# divide the megaline dataset into 60% for training and 40% for (validation + test)\n",
    "df_train, df_temp = train_test_split(df_megaline, test_size=0.6, random_state=147)\n",
    "\n",
    "# divide the temporary dataset into 50% for validation and 50% for test\n",
    "df_validation, df_test = train_test_split(df_temp, test_size=0.5, random_state=147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_train: (1285, 4)\n",
      "target_train: (1285,) \n",
      "\n",
      "features_valid: (964, 4)\n",
      "target_valid: (964,) \n",
      "\n",
      "features_test: (965, 4)\n",
      "target_test: (965,)\n"
     ]
    }
   ],
   "source": [
    "# divide the training dataset into features and targets\n",
    "features_train = df_train.drop(['is_ultra'],axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "# split the validation dataset into features and targets\n",
    "features_valid = df_validation.drop(['is_ultra'],axis=1)\n",
    "target_valid = df_validation['is_ultra']\n",
    "\n",
    "# divide the test dataset into features and targets\n",
    "features_test = df_test.drop(['is_ultra'],axis=1)\n",
    "target_test = df_test['is_ultra']\n",
    "\n",
    "# displays the shape of the training and validation\n",
    "print('features_train:',features_train.shape)\n",
    "print('target_train:',target_train.shape,'\\n')\n",
    "\n",
    "print('features_valid:',features_valid.shape)\n",
    "print('target_valid:',target_valid.shape,'\\n')\n",
    "\n",
    "print('features_test:',features_test.shape)\n",
    "print('target_test:',target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Machine Learning Algorithms <a id='cont_8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the types of features and target in the previous dataset division, we conclude that the `machine learning model` that can be made is of the `supervised learning - classification` type. Let's train and test the aforementioned models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification Algorithm <a id='cont_9'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will test the `decision tree classification algorithm` where `hyperparameter` for the depth of the tree will be tested to get the best `hyperparameter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy (Decision Tree)\n",
      "Accuracy: 0.79876\n",
      "Depth\t: 3\n"
     ]
    }
   ],
   "source": [
    "# decision tree algorithm experiment\n",
    "\n",
    "# create a temporary variable\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "\n",
    "# testing the depth of the decision tree model (depth -> 1 ~ 50)\n",
    "for depth in range(1, 51):\n",
    "     # create a decision tree model\n",
    "     model = DecisionTreeClassifier(random_state=147, max_depth=depth)\n",
    "     # train the model using features and target train\n",
    "     model.fit(features_train, target_train)\n",
    "     # calculate accuracy using features and target validation\n",
    "     result = model.score(features_valid,target_valid)\n",
    "     if result > best_result:\n",
    "         best_model = model\n",
    "         best_result = result\n",
    "         best_depth = depth\n",
    "\n",
    "# displays the output\n",
    "print(\"Best Model Accuracy (Decision Tree)\")\n",
    "print(f\"Accuracy: {best_result:.5f}\")\n",
    "print(f\"Depth\\t: {best_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can see that the best accuracy score obtained was `79.88%` at a `depth` tree of `3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification Algorithm <a id='cont_10'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, we will test the `decision tree classification algorithm` where the `hyperparameter` for the `random forest` that we are `tuning` is the number of trees `n_estimators` and the depth of the tree `depth`.\n",
    "\n",
    "Here we will try for a tree depth of `1 to 10`, and for the number of trees `1 to 15` we will find the best `hyperparameter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy (Random Forest)\n",
      "Accuracy\t: 0.81017\n",
      "Depth\t\t: 7\n",
      "N_Estimators\t: 6\n"
     ]
    }
   ],
   "source": [
    "# Experimental random forest algorithm\n",
    "# tree depth: depth -> 1 ~ 10\n",
    "# number of trees: n_estimators -> 1 ~ 15\n",
    "\n",
    "# create a temporary variable\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "\n",
    "# testing the depth of the model and the number of trees\n",
    "# setting the number of trees\n",
    "for est in range(1, 16):\n",
    "     # setting the amount of tree depth\n",
    "     for depth in range (1, 11):\n",
    "         # create a random forest classifier model\n",
    "         model = RandomForestClassifier(random_state=147, n_estimators=est, max_depth=depth)\n",
    "         # train the model using features and target train\n",
    "         model.fit(features_train, target_train)\n",
    "         # calculate accuracy using features and target validation\n",
    "         result = model.score(features_valid,target_valid)\n",
    "         if result > best_result:\n",
    "             best_result = result\n",
    "             best_est = est\n",
    "             best_depth = depth\n",
    "\n",
    "# displays the output\n",
    "print(\"Best Model Accuracy (Random Forest)\")\n",
    "print(f\"Accuracy\\t: {best_result:.5f}\")\n",
    "print(f\"Depth\\t\\t: {best_depth}\")\n",
    "print(f\"N_Estimators\\t: {best_est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that we can get an accuracy score of `81.02%` using only `7` tree depth and `6` tree count.\n",
    "\n",
    "Let's try increasing the `hyperparameter` to see if we can get a better accuracy score than this score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to increase the depth of the trees `1 to 20`, and the number of trees `1 to 70 (in increments of 5)` for which we will find the best `hyperparameter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy (Random Forest)\n",
      "Accuracy\t: 0.81535\n",
      "Depth\t\t: 9\n",
      "N_Estimators\t: 51\n"
     ]
    }
   ],
   "source": [
    "# Experimental random forest algorithm\n",
    "# tree depth: depth -> 1 ~ 20\n",
    "# number of trees: n_estimators -> 1 ~ 70 {increment 5}\n",
    "\n",
    "# create temporary\n",
    "best_result = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "\n",
    "# testing the depth of the model and the number of trees\n",
    "# setting the number of trees\n",
    "for est in range(1, 71, 5):\n",
    "     # setting the amount of tree depth\n",
    "     for depth in range(1, 21):\n",
    "         # create a random forest classifier model\n",
    "         model = RandomForestClassifier(random_state=147, n_estimators=est, max_depth=depth)\n",
    "         # train the model using features and target train\n",
    "         model.fit(features_train, target_train)\n",
    "         # calculate accuracy using features and target validation\n",
    "         result = model.score(features_valid,target_valid)\n",
    "         if result > best_result:\n",
    "             best_result = result\n",
    "             best_est = est\n",
    "             best_depth = depth\n",
    "\n",
    "# displays the output\n",
    "print(\"Best Model Accuracy (Random Forest)\")\n",
    "print(f\"Accuracy\\t: {best_result:.5f}\")\n",
    "print(f\"Depth\\t\\t: {best_depth}\")\n",
    "print(f\"N_Estimators\\t: {best_est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that we can get an accuracy score of `81.53%` using only `9` tree depth and `51` tree count.\n",
    "\n",
    "Here we conclude that the higher the `hyperparameter` does not cause a significant increase in the accuracy of the score, in fact it is almost the same. So we take the best `hyperparameter` for the `random forest` algorithm this time at a tree depth of `7` and number of trees `6`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Algorithm <a id='cont_11'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way we will test the `logistic regression algorithm` using the 'liblinear' `solver`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy (Logistic Regression)\n",
      "Accuracy: 0.72822\n"
     ]
    }
   ],
   "source": [
    "# logistic regression algorithm experiments\n",
    "\n",
    "# create a logistic regression model\n",
    "model = LogisticRegression(random_state=147, solver='liblinear')\n",
    "\n",
    "# train the model using features and target train\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# calculate accuracy using features and target validation\n",
    "result = model.score(features_valid,target_valid)\n",
    "\n",
    "# displays the output\n",
    "print(\"Best Model Accuracy (Logistic Regression)\")\n",
    "print(f\"Accuracy: {result:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get a lower score than the two previous algorithms that we tested, which is only `72.8%`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model With Best Algorithm <a id='cont_12'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous tests, we chose the best algorithm with its `hyperparameter` which is the `Random Forest Classification Algorithm` with a `depth` tree depth of `7` and a total of `6` trees.\n",
    "\n",
    "The model only uses `60%` of the dataset as an exercise, what if we increase it to `80%`, of course we hope that the model will be able to predict better.\n",
    "\n",
    "Let's combine the training and validation datasets into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Dataset: (2249, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=7, n_estimators=6, random_state=147)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=7, n_estimators=6, random_state=147)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=7, n_estimators=6, random_state=147)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using training and validation datasets to get more accurate results using random forests\n",
    "\n",
    "# combine training and validation datasets\n",
    "merge_df = pd.concat([df_train,df_validation],axis=0)\n",
    "print('New Dataset:',merge_df.shape)\n",
    "\n",
    "# split the final dataset into features and targets\n",
    "features = merge_df.drop(['is_ultra'],axis=1)\n",
    "target = merge_df['is_ultra']\n",
    "\n",
    "# max_depth = 7\n",
    "#n_estimators = 6\n",
    "best_model = RandomForestClassifier(random_state=147, n_estimators=6, max_depth=7)\n",
    "\n",
    "# train the best models\n",
    "best_model. fit(features,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Feasibility of the Model (Sanity Check) <a id='cont_13'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the feasibility of the `sanity check` using the `testing dataset` that has been made before where the correct answer was not entered during the training of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_model accuracy: 0.8072538860103627\n"
     ]
    }
   ],
   "source": [
    "# model feasibility test (sanity check)\n",
    "accuracy = best_model.score(features_test,target_test)\n",
    "\n",
    "# displays the output\n",
    "print(\"Best_model accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the accuracy is still around `81%` and is still above the `75%` accuracy threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Machine Learning Model <a id='cont_14'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create any dataset where we will know which package is suitable if we have the following features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>85</td>\n",
       "      <td>35</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>60</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages  mb_used\n",
       "0     70      100        50    10000\n",
       "1     20       85        35      500\n",
       "2     50      300       300     7000\n",
       "3    100      250        60     3000\n",
       "4     90       30       500     1000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an arbitrary dataframe to test the selected model\n",
    "data_test = pd.DataFrame({\n",
    "    'calls':[70,20,50,100,90],\n",
    "    'minutes':[100,85,300,250,30],\n",
    "    'messages':[50,35,300,60,500],\n",
    "    'mb_used':[10000,500,7000,3000,1000]\n",
    "})\n",
    "\n",
    "# display dataframes\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the packages for these five users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict data_test\n",
    "best_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that we can predict users who use the `smart` package as many as 2 users and the `ultra` package as many as 3 users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Conclusion <a id='cont_15'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this project we have loaded the necessary libraries, prepared the dataset, divided the dataset, trained and tested a `machine learning model` to predict which packages are recommended to users based on user behavior. It can be concluded as follows:\n",
    "- The dataset for training and testing the `machine learning` model is divided into `60%` for `training`, `20%` for `validation` and `20%` for `testing`.\n",
    "- Algorithms tested include: `Decision Tree Classification`, `Random Forest Classification` and `Logistic Regression`.\n",
    "- The best algorithm with its `hyperparameter` is the `Random Forest Classification Algorithm` with a `depth` of `7` trees and `6` of trees resulting in an accuracy of `81%`.\n",
    "- A `Sanity Check` feasibility test was performed and the model was able to maintain its score accuracy of `81%`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
